{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64db31a9",
   "metadata": {},
   "source": [
    "# Programming Assignment 2 - PRML\n",
    "### UBIT: haudipud  \n",
    "### UB ID: 50599797\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa08c1aa",
   "metadata": {},
   "source": [
    "## Section 1: Binary Classification (30 marks)\n",
    "- Dataset: `abalone.csv`\n",
    "- Task: Predict if abalone is older than 10 years (rings > 8.5)\n",
    "- Model: Logistic Regression (from `prml.linear`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8a8ed6a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T15:50:28.146917Z",
     "start_time": "2025-04-03T15:50:27.105044Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "df = pd.read_csv('abalone.csv')\n",
    "df['age'] = df['rings'] + 1.5\n",
    "df['binary_label'] = (df['age'] > 10).astype(int)\n",
    "\n",
    "\n",
    "X = df.drop(columns=['rings', 'age', 'binary_label'])\n",
    "y = df['binary_label']\n",
    "\n",
    "\n",
    "if X['class'].dtype == object:\n",
    "    X = pd.get_dummies(X, columns=['class'], drop_first=True)\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b4c5ef7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T15:50:28.356486Z",
     "start_time": "2025-04-03T15:50:28.153962Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8002\n",
      "\n",
      "Confusion Matrix:\n",
      " [[234  45]\n",
      " [122 435]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.84      0.74       279\n",
      "           1       0.91      0.78      0.84       557\n",
      "\n",
      "    accuracy                           0.80       836\n",
      "   macro avg       0.78      0.81      0.79       836\n",
      "weighted avg       0.82      0.80      0.80       836\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from prml.linear import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.classify(X_test)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {acc:.4f}\\n\")\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "print(\"\\nClassification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ddc1ef3-b510-4fa6-8378-8529db1577e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /opt/anaconda3/lib/python3.12/site-packages (2.6.0)\n",
      "Requirement already satisfied: torchvision in /opt/anaconda3/lib/python3.12/site-packages (0.21.0)\n",
      "Requirement already satisfied: torchaudio in /opt/anaconda3/lib/python3.12/site-packages (2.6.0)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/anaconda3/lib/python3.12/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.12/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.12/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/lib/python3.12/site-packages (from torch) (2024.12.0)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.12/site-packages (from torch) (75.8.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/anaconda3/lib/python3.12/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.12/site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from torchvision) (11.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch torchvision torchaudio\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de7290d",
   "metadata": {},
   "source": [
    "## Section 2: Multi-class Classification (30 marks)\n",
    "- Dataset: `abalone.csv`\n",
    "- Task: Predict age group: young (<=8), adult (9â€“11), old (>=12)\n",
    "- Model: Softmax Regression (from `prml.linear`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab9eac90",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['age_group'] = pd.cut(df['rings'], bins=[0, 8, 11, df['rings'].max()], labels=[0,1,2]).astype(int)\n",
    "X_multi = df.drop(columns=['rings', 'age', 'binary_label', 'age_group'])\n",
    "y_multi = df['age_group']\n",
    "\n",
    "\n",
    "if X_multi['class'].dtype == object:\n",
    "    X_multi = pd.get_dummies(X_multi, columns=['class'], drop_first=True)\n",
    "\n",
    "\n",
    "X_multi_scaled = scaler.fit_transform(X_multi)\n",
    "\n",
    "\n",
    "X_train_m, X_test_m, y_train_m, y_test_m = train_test_split(X_multi_scaled, y_multi, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a71f837f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5096\n",
      "\n",
      "Confusion Matrix:\n",
      " [[230  22  27]\n",
      " [ 91  48 235]\n",
      " [ 20  15 148]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.82      0.74       279\n",
      "           1       0.56      0.13      0.21       374\n",
      "           2       0.36      0.81      0.50       183\n",
      "\n",
      "    accuracy                           0.51       836\n",
      "   macro avg       0.53      0.59      0.48       836\n",
      "weighted avg       0.56      0.51      0.45       836\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from prml.linear import SoftmaxRegression\n",
    "\n",
    "model_multi = SoftmaxRegression()\n",
    "model_multi.fit(X_train_m, y_train_m)\n",
    "y_pred_m = model_multi.classify(X_test_m)\n",
    "\n",
    "acc_m = accuracy_score(y_test_m, y_pred_m)\n",
    "cm_m = confusion_matrix(y_test_m, y_pred_m)\n",
    "report_m = classification_report(y_test_m, y_pred_m)\n",
    "\n",
    "print(f\"Accuracy: {acc_m:.4f}\\n\")\n",
    "print(\"Confusion Matrix:\\n\", cm_m)\n",
    "print(\"\\nClassification Report:\\n\", report_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99ff7a4",
   "metadata": {},
   "source": [
    "## Section 3: Neural Networks (20 marks)\n",
    "- Dataset: `bonus.csv`\n",
    "- Task: Predict wine `quality` using a neural network\n",
    "- Model: Feedforward Neural Network (PyTorch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "edc0dcda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30, Loss: 1.9269\n",
      "Epoch 10/30, Loss: 1.5156\n",
      "Epoch 15/30, Loss: 1.3046\n",
      "Epoch 20/30, Loss: 1.2432\n",
      "Epoch 25/30, Loss: 1.1866\n",
      "Epoch 30/30, Loss: 1.1375\n",
      "\n",
      "Accuracy: 0.5449\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         5\n",
      "           4       1.00      0.04      0.08        25\n",
      "           5       0.58      0.65      0.61       291\n",
      "           6       0.53      0.67      0.59       432\n",
      "           7       0.52      0.30      0.38       192\n",
      "           8       0.00      0.00      0.00        35\n",
      "\n",
      "    accuracy                           0.54       980\n",
      "   macro avg       0.44      0.27      0.28       980\n",
      "weighted avg       0.53      0.54      0.52       980\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "bonus_df = pd.read_csv('bonus.csv')\n",
    "X = bonus_df.drop(columns=['quality'])\n",
    "y = bonus_df['quality']\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train.values, dtype=torch.long)\n",
    "y_test = torch.tensor(y_test.values, dtype=torch.long)\n",
    "\n",
    "\n",
    "class FeedforwardNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "input_dim = X_train.shape[1]\n",
    "hidden_dim = 32\n",
    "output_dim = y.max() + 1\n",
    "\n",
    "\n",
    "model = FeedforwardNN(input_dim, hidden_dim, output_dim)\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "epochs = 30\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_train)\n",
    "    loss = criterion(outputs, y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if (epoch+1) % 5 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X_test).argmax(dim=1)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(f\"\\nAccuracy: {acc:.4f}\")\n",
    "    print(\"\\nClassification Report:\\n\")\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4514cfb",
   "metadata": {},
   "source": [
    "## Section 4: Convolutional Neural Networks (20 marks)\n",
    "- Dataset: Image folders (`train/` and `test/`)\n",
    "- Classes: `adidas`, `converse`, `nike`\n",
    "- Task: Classify images using a CNN\n",
    "- Model: PyTorch CNN with Conv2D + ReLU + MaxPool + FC layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d47dbe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 25.7398\n",
      "Epoch 2, Loss: 24.9600\n",
      "Epoch 3, Loss: 23.9473\n",
      "Epoch 4, Loss: 23.0536\n",
      "Epoch 5, Loss: 21.8075\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      adidas       0.46      0.76      0.57        38\n",
      "    converse       0.71      0.13      0.22        38\n",
      "        nike       0.52      0.61      0.56        38\n",
      "\n",
      "    accuracy                           0.50       114\n",
      "   macro avg       0.57      0.50      0.45       114\n",
      "weighted avg       0.57      0.50      0.45       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_dataset = datasets.ImageFolder(root='cnn_data/train', transform=transform)\n",
    "test_dataset = datasets.ImageFolder(root='cnn_data/test', transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(32 * 16 * 16, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 3)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = CNN()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(5):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {running_loss:.4f}\")\n",
    "\n",
    "\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        all_preds.extend(preds.numpy())\n",
    "        all_labels.extend(labels.numpy())\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(all_labels, all_preds, target_names=train_dataset.classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31549f2",
   "metadata": {},
   "source": [
    "## Section 5: Bonus - Multi-class Classification using Sklearn (10 marks)\n",
    "- Dataset: `bonus.csv`\n",
    "- Task: Predict wine `quality` using any `sklearn` classifier\n",
    "- Model: RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "285c5523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6939\n",
      "\n",
      "Confusion Matrix:\n",
      " [[  0   0   3   2   0   0]\n",
      " [  0   5  12   8   0   0]\n",
      " [  0   4 203  82   2   0]\n",
      " [  0   0  63 344  25   0]\n",
      " [  0   0   3  73 112   4]\n",
      " [  0   0   1  12   6  16]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         5\n",
      "           4       0.56      0.20      0.29        25\n",
      "           5       0.71      0.70      0.70       291\n",
      "           6       0.66      0.80      0.72       432\n",
      "           7       0.77      0.58      0.66       192\n",
      "           8       0.80      0.46      0.58        35\n",
      "\n",
      "    accuracy                           0.69       980\n",
      "   macro avg       0.58      0.46      0.49       980\n",
      "weighted avg       0.70      0.69      0.69       980\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "\n",
    "bonus_df = pd.read_csv('bonus.csv')\n",
    "X = bonus_df.drop(columns=['quality'])\n",
    "y = bonus_df['quality']\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {acc:.4f}\\n\")\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436ba379-8d67-4919-bb5d-086a940cae8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
