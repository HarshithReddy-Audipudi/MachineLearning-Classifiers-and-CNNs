{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64db31a9",
   "metadata": {},
   "source": [
    "# Programming Assignment 2 - PRML\n",
    "### UBIT: haudipud  \n",
    "### UB ID: 50599797\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa08c1aa",
   "metadata": {},
   "source": [
    "## Section 1: Binary Classification (30 marks)\n",
    "- Dataset: `abalone.csv`\n",
    "- Task: Predict if abalone is older than 10 years (rings > 8.5)\n",
    "- Model: Logistic Regression (from `prml.linear`)\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "a8a8ed6a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T15:50:28.146917Z",
     "start_time": "2025-04-03T15:50:27.105044Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('abalone.csv')\n",
    "df['age'] = df['rings'] + 1.5\n",
    "df['binary_label'] = (df['age'] > 10).astype(int)\n",
    "\n",
    "# Drop unused columns\n",
    "X = df.drop(columns=['rings', 'age', 'binary_label'])\n",
    "y = df['binary_label']\n",
    "\n",
    "# One-hot encoding for 'class' column\n",
    "if X['class'].dtype == object:\n",
    "    X = pd.get_dummies(X, columns=['class'], drop_first=True)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "0b4c5ef7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T15:50:28.356486Z",
     "start_time": "2025-04-03T15:50:28.153962Z"
    }
   },
   "source": [
    "# Logistic Regression from PRML\n",
    "from prml.linear import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.classify(X_test)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {acc:.4f}\\n\")\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "print(\"\\nClassification Report:\\n\", report)"
   ],
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "`np.Inf` was removed in the NumPy 2.0 release. Use `np.inf` instead.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Logistic Regression from PRML\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mprml\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mlinear\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m LogisticRegression\n\u001B[1;32m      4\u001B[0m model \u001B[38;5;241m=\u001B[39m LogisticRegression()\n\u001B[1;32m      5\u001B[0m model\u001B[38;5;241m.\u001B[39mfit(X_train, y_train)\n",
      "File \u001B[0;32m~/Downloads/prml/__init__.py:1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mprml\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[1;32m      2\u001B[0m     bayesnet,\n\u001B[1;32m      3\u001B[0m     clustering,\n\u001B[1;32m      4\u001B[0m     dimreduction,\n\u001B[1;32m      5\u001B[0m     kernel,\n\u001B[1;32m      6\u001B[0m     linear,\n\u001B[1;32m      7\u001B[0m     markov,\n\u001B[1;32m      8\u001B[0m     nn,\n\u001B[1;32m      9\u001B[0m     rv,\n\u001B[1;32m     10\u001B[0m     sampling\n\u001B[1;32m     11\u001B[0m )\n\u001B[1;32m     14\u001B[0m __all__ \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m     15\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbayesnet\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     16\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mclustering\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     23\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msampling\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     24\u001B[0m ]\n",
      "File \u001B[0;32m~/Downloads/prml/kernel/__init__.py:8\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mprml\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mkernel\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mrelevance_vector_classifier\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m RelevanceVectorClassifier\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mprml\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mkernel\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mrelevance_vector_regressor\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m RelevanceVectorRegressor\n\u001B[0;32m----> 8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mprml\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mkernel\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msupport_vector_classifier\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m SupportVectorClassifier\n\u001B[1;32m     11\u001B[0m __all__ \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m     12\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPolynomialKernel\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     13\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRBF\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     18\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSupportVectorClassifier\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     19\u001B[0m ]\n",
      "File \u001B[0;32m~/Downloads/prml/kernel/support_vector_classifier.py:4\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[0;32m----> 4\u001B[0m \u001B[38;5;28;01mclass\u001B[39;00m \u001B[38;5;21;01mSupportVectorClassifier\u001B[39;00m(\u001B[38;5;28mobject\u001B[39m):\n\u001B[1;32m      6\u001B[0m     \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, kernel, C\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39mInf):\n\u001B[1;32m      7\u001B[0m \u001B[38;5;250m        \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;124;03m        construct support vector classifier\u001B[39;00m\n\u001B[1;32m      9\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     15\u001B[0m \u001B[38;5;124;03m            penalty of misclassification\u001B[39;00m\n\u001B[1;32m     16\u001B[0m \u001B[38;5;124;03m        \"\"\"\u001B[39;00m\n",
      "File \u001B[0;32m~/Downloads/prml/kernel/support_vector_classifier.py:6\u001B[0m, in \u001B[0;36mSupportVectorClassifier\u001B[0;34m()\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mclass\u001B[39;00m \u001B[38;5;21;01mSupportVectorClassifier\u001B[39;00m(\u001B[38;5;28mobject\u001B[39m):\n\u001B[0;32m----> 6\u001B[0m     \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, kernel, C\u001B[38;5;241m=\u001B[39m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mInf\u001B[49m):\n\u001B[1;32m      7\u001B[0m \u001B[38;5;250m        \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;124;03m        construct support vector classifier\u001B[39;00m\n\u001B[1;32m      9\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     15\u001B[0m \u001B[38;5;124;03m            penalty of misclassification\u001B[39;00m\n\u001B[1;32m     16\u001B[0m \u001B[38;5;124;03m        \"\"\"\u001B[39;00m\n\u001B[1;32m     17\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mkernel \u001B[38;5;241m=\u001B[39m kernel\n",
      "File \u001B[0;32m/Library/Python/3.9/site-packages/numpy/__init__.py:397\u001B[0m, in \u001B[0;36m__getattr__\u001B[0;34m(attr)\u001B[0m\n\u001B[1;32m    394\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m(__former_attrs__[attr])\n\u001B[1;32m    396\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m attr \u001B[38;5;129;01min\u001B[39;00m __expired_attributes__:\n\u001B[0;32m--> 397\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m(\n\u001B[1;32m    398\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`np.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mattr\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m` was removed in the NumPy 2.0 release. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    399\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m__expired_attributes__[attr]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    400\u001B[0m     )\n\u001B[1;32m    402\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m attr \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mchararray\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m    403\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[1;32m    404\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`np.chararray` is deprecated and will be removed from \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    405\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mthe main namespace in the future. Use an array with a string \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    406\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mor bytes dtype instead.\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;167;01mDeprecationWarning\u001B[39;00m, stacklevel\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m)\n",
      "\u001B[0;31mAttributeError\u001B[0m: `np.Inf` was removed in the NumPy 2.0 release. Use `np.inf` instead."
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "8de7290d",
   "metadata": {},
   "source": [
    "## Section 2: Multi-class Classification (30 marks)\n",
    "- Dataset: `abalone.csv`\n",
    "- Task: Predict age group: young (<=8), adult (9–11), old (>=12)\n",
    "- Model: Softmax Regression (from `prml.linear`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9eac90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create age group classes: 0 = young (<=8), 1 = adult (9–11), 2 = old (>=12)\n",
    "df['age_group'] = pd.cut(df['rings'], bins=[0, 8, 11, df['rings'].max()], labels=[0,1,2]).astype(int)\n",
    "X_multi = df.drop(columns=['rings', 'age', 'binary_label', 'age_group'])\n",
    "y_multi = df['age_group']\n",
    "\n",
    "# One-hot encoding\n",
    "if X_multi['class'].dtype == object:\n",
    "    X_multi = pd.get_dummies(X_multi, columns=['class'], drop_first=True)\n",
    "\n",
    "# Scale features\n",
    "X_multi_scaled = scaler.fit_transform(X_multi)\n",
    "\n",
    "# Train-test split\n",
    "X_train_m, X_test_m, y_train_m, y_test_m = train_test_split(X_multi_scaled, y_multi, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71f837f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prml.linear import SoftmaxRegression\n",
    "\n",
    "model_multi = SoftmaxRegression()\n",
    "model_multi.fit(X_train_m, y_train_m)\n",
    "y_pred_m = model_multi.classify(X_test_m)\n",
    "\n",
    "acc_m = accuracy_score(y_test_m, y_pred_m)\n",
    "cm_m = confusion_matrix(y_test_m, y_pred_m)\n",
    "report_m = classification_report(y_test_m, y_pred_m)\n",
    "\n",
    "print(f\"Accuracy: {acc_m:.4f}\\n\")\n",
    "print(\"Confusion Matrix:\\n\", cm_m)\n",
    "print(\"\\nClassification Report:\\n\", report_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99ff7a4",
   "metadata": {},
   "source": [
    "## Section 3: Neural Networks (20 marks)\n",
    "- Dataset: `bonus.csv`\n",
    "- Task: Predict wine `quality` using a neural network\n",
    "- Model: Feedforward Neural Network (PyTorch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc0dcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "bonus_df = pd.read_csv('bonus.csv')\n",
    "X = bonus_df.drop(columns=['quality'])\n",
    "y = bonus_df['quality']\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train.values, dtype=torch.long)\n",
    "y_test = torch.tensor(y_test.values, dtype=torch.long)\n",
    "\n",
    "# Define the model\n",
    "class FeedforwardNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "# Instantiate model\n",
    "input_dim = X_train.shape[1]\n",
    "hidden_dim = 32\n",
    "output_dim = len(y.unique())\n",
    "model = FeedforwardNN(input_dim, hidden_dim, output_dim)\n",
    "\n",
    "# Train the model\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "epochs = 30\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_train)\n",
    "    loss = criterion(outputs, y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if (epoch+1) % 5 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X_test).argmax(dim=1)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(f\"\\nAccuracy: {acc:.4f}\")\n",
    "    print(\"\\nClassification Report:\\n\")\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4514cfb",
   "metadata": {},
   "source": [
    "## Section 4: Convolutional Neural Networks (20 marks)\n",
    "- Dataset: Image folders (`train/` and `test/`)\n",
    "- Classes: `adidas`, `converse`, `nike`\n",
    "- Task: Classify images using a CNN\n",
    "- Model: PyTorch CNN with Conv2D + ReLU + MaxPool + FC layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d47dbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Define transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Load datasets from folders\n",
    "train_dataset = datasets.ImageFolder(root='train', transform=transform)\n",
    "test_dataset = datasets.ImageFolder(root='test', transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Define CNN\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(32 * 16 * 16, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 3)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Train the CNN\n",
    "model = CNN()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(5):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {running_loss:.4f}\")\n",
    "\n",
    "# Evaluate on test set\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        all_preds.extend(preds.numpy())\n",
    "        all_labels.extend(labels.numpy())\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(all_labels, all_preds, target_names=train_dataset.classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31549f2",
   "metadata": {},
   "source": [
    "## Section 5: Bonus - Multi-class Classification using Sklearn (10 marks)\n",
    "- Dataset: `bonus.csv`\n",
    "- Task: Predict wine `quality` using any `sklearn` classifier\n",
    "- Model: RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285c5523",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Load and split data\n",
    "bonus_df = pd.read_csv('bonus.csv')\n",
    "X = bonus_df.drop(columns=['quality'])\n",
    "y = bonus_df['quality']\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train model\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {acc:.4f}\\n\")\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
